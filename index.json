
    
    
    
    
    
    
    
    
    
    [{"authors":null,"categories":null,"content":"Welcome! I am a Research Fellow at the School of Computing Technologies, RMIT University, Melbourne, Australia. My research focuses on search systems and their evaluation, with particular attention to Information Retrieval.\nDuring my Ph.D. under the guidance of Profs. J. Shane Culpepper and Falk Scholer, I focused on Query Performance Prediction (QPP). My thesis aimed to advance the understanding and evaluation of QPP. Currently, I am exploring how end-to-end search pipelines and user behavior analysis can improve system effectiveness and user experience. Beyond QPP, I utilize empirical experimentation, statistical analysis, and machine learning models to gain deeper insights into these areas.\nMy M.Sc. thesis at the Technion — Israel Institute of Technology, supervised by Prof. Oren Kurland, focused on enhancing QPP using reference queries.\nOutside of academia, I enjoy hiking, biking, and spending quality time with my family and our dog, Quan. I also volunteer with Guide Dogs Victoria, where I have been both a puppy raiser and a temporary carer, supporting a cause close to my heart.\nIf you are interested in Information Retrieval or wish to collaborate on research, please feel free to reach out to me via email or social media. I am always happy to explore new opportunities for collaboration and knowledge exchange.\n","date":1727913600,"expirydate":-62135596800,"kind":"term","lang":"en","lastmod":1727913600,"objectID":"2525497d367e79493fd32b198b28f040","permalink":"","publishdate":"0001-01-01T00:00:00Z","relpermalink":"","section":"authors","summary":"Welcome! I am a Research Fellow at the School of Computing Technologies, RMIT University, Melbourne, Australia. My research focuses on search systems and their evaluation, with particular attention to Information Retrieval.","tags":null,"title":"Oleg Zendel","type":"authors"},{"authors":["Oleg Zendel","J. Shane Culpepper","Falk Scholer","Paul Thomas"],"categories":[],"content":"","date":1727913600,"expirydate":-62135596800,"kind":"page","lang":"en","lastmod":1727913600,"objectID":"67f42c73b7524ba98ece4776f36b1824","permalink":"https://zendelo.github.io/publication/gptcognitive/","publishdate":"2024-01-10T02:12:08.426039Z","relpermalink":"/publication/gptcognitive/","section":"publication","summary":"Large language models (LLMs) are capable of assessing document and query characteristics, including relevance, and are now being used for a variety of different classification labeling tasks as well. This study explores how to use LLMs to classify an *information need*, often represented as a user query. In particular, our goal is to classify the cognitive complexity of the search task for a  given ``backstory''. Using 180 TREC topics and backstories, we show that GPT-based LLMs agree with human experts as much as other human experts. We also show that batching and ordering can significantly impact the accuracy of GPT-3.5, but rarely alter the quality of GPT-4 predictions. This study provides insights into the efficacy of large language models for annotation tasks normally completed by humans, and offers recommendations for other similar applications. ","tags":["\"Cognitive task complexity; large language models; search task classification; cognitive task complexity; GPT models for classification\""],"title":"Enhancing Human Annotation: Leveraging Large Language Models and Efficient Batch Processing?","type":"publication"},{"authors":["Oleg Zendel","Melika P. Ebrahim","J. Shane Culpepper","Alistair Moffat","Falk Scholer"],"categories":[],"content":"","date":1640995200,"expirydate":-62135596800,"kind":"page","lang":"en","lastmod":1650593530,"objectID":"44e09ba3be88c829ce92a1a0439eb61b","permalink":"https://zendelo.github.io/publication/zendel-2022/","publishdate":"2022-04-22T02:12:08.426039Z","relpermalink":"/publication/zendel-2022/","section":"publication","summary":"Any given information need can be expressed via a wide range of possible queries. Recent work with such query variations has demonstrated that different queries can fetch notably divergent sets of documents, even when the queries have identical intents and superficial similarity. That is, different users might receive SERPs of quite different effectiveness for the same information need. That observation then raises an interesting question: do users have a sense of how useful any given query will be? Can they anticipate the effectiveness of alternative queries for the same retrieval need? To explore that question we designed and carried out a crowd-sourced user study in which we asked subjects to consider an information need statement expressed as a backstory, and then provide their opinions as to the relative usefulness of a set of queries ostensibly addressing that objective. We solicited opinions using two different interfaces: one that collected absolute ratings of queries, and one that required that the subjects place a set of queries into ``order''. We found that crowd workers are reasonably consistent in their estimates of how effective queries are likely to be, and also that their estimates correlate positively with actual system performance.","tags":["\"Query variations; query performance prediction\""],"title":"Can Users Predict Relative Query Effectiveness?","type":"publication"},{"authors":["Guglielmo Faggioli","Oleg Zendel","J. Shane Culpepper","Nicola Ferro","Falk Scholer"],"categories":[],"content":"","date":1640995200,"expirydate":-62135596800,"kind":"page","lang":"en","lastmod":1650602914,"objectID":"62f48bee5169f8178db54f7bbb03467c","permalink":"https://zendelo.github.io/publication/faggioli-irj-2022/","publishdate":"2022-03-07T04:48:32.688153Z","relpermalink":"/publication/faggioli-irj-2022/","section":"publication","summary":"Query performance prediction (QPP) has been studied extensively in the IR community over the last two decades. A by-product of this research is a methodology to evaluate the effectiveness of QPP techniques. In this paper, we re-examine the existing evaluation methodology commonly used for QPP, and propose a new approach. Our key idea is to model QPP performance as a distribution instead of relying on point estimates. To obtain such distribution, we exploit the scaled Absolute Ranking Error (sARE) measure, and its mean the scaled Mean Absolute Ranking Error (sMARE). Our work demonstrates important statistical implications, and overcomes key limitations imposed by the currently used correlation-based point-estimate evaluation approaches. We also explore the potential benefits of using multiple query formulations and ANalysis Of VAriance (ANOVA) modeling in order to measure interactions between multiple factors. The resulting statistical analysis combined with a novel evaluation framework demonstrates the merits of modeling QPP performance as distributions, and enables detailed statistical ANOVA models for comparative analyses to be created.","tags":["\"Analysis of variance\"","\"Information retrieval\"","\"Query formulations\"","\"Query performance prediction\"","\"Systems evaluation\""],"title":"sMARE: a new paradigm to evaluate and understand query performance prediction methods","type":"publication"},{"authors":["Oleg Zendel","J. Shane Culpepper","Falk Scholer"],"categories":[],"content":"","date":1620691200,"expirydate":-62135596800,"kind":"page","lang":"en","lastmod":1620697301,"objectID":"40aead024dc864d3dfef43b7e08d6160","permalink":"https://zendelo.github.io/publication/interintraqpp/","publishdate":"2021-05-11T00:00:00Z","relpermalink":"/publication/interintraqpp/","section":"publication","summary":"Accurately estimating the retrieval effectiveness of different queries representing distinct information needs is a problem in Information Retrieval (IR) that has been studied for over 20 years. Recent work showed that the problem can be significantly harder when multiple queries representing the same information need are used in prediction. By generalizing the existing evaluation framework of Query Performance Prediction (QPP) we explore the causes of these differences in prediction quality in the two scenarios. Our empirical analysis demonstrates that for most predictors, this difference is solely an artifact of the underlying differences in the query effectiveness distributions. Our detailed analysis also demonstrates key performance distribution properties under which QPP is most and least reliable.","tags":["\"Query Performance Prediction\"","\"Evaluation\"","\"Query Variations\""],"title":"Is Query Performance Prediction With Multiple Query Variations Harder Than Topic Performance Prediction?","type":"publication"},{"authors":["Oleg Zendel"],"categories":[],"content":"","date":1620604800,"expirydate":-62135596800,"kind":"page","lang":"en","lastmod":1620604800,"objectID":"60904761d8f2406f748732bac785b5b3","permalink":"https://zendelo.github.io/publication/dcsigir/","publishdate":"2021-05-10T00:00:00Z","relpermalink":"/publication/dcsigir/","section":"publication","summary":"The research on Query Performance Prediction (QPP) focuses on estimating the effectiveness of retrieval results in the absence of human relevance judgments. Accurately estimating the result of a search performed in response to a query has been extensively studied over the past two decades. With the rising popularity of virtual assistants along with evolving research on complex informa- tion needs, the need for reliable QPP methods as well as the number of potential applications significantly increases. In this work, we focus on improving the evaluation framework of QPP. As we see the existing evaluation as a considerable limitation in the improvement of QPP methods, a reliable and improved evaluation framework would constitute a stepping-stone for a breakthrough in QPP. The existing evaluation framework in QPP mainly relies on the measurement of the correlation coefficient between the per-query prediction scores and the actual per-query system effectiveness measure, usually Average Precision (AP). The QPP method that achieves higher correlation is considered to be superior. However, Hauff et al. demonstrate that higher correlation does not vouch for more accurate prediction. The authors additionally advocate the usage of Fisher’s 𝑧 transformation and Confidence Intervals (CIs) to determine statistically significant differences between multiple correlation coefficients. Furthermore, the existing evaluation methodology is true only per a specific combination of a corpus, retrieval method, and set of queries; and does not necessarily hold if any of these is changed. That is, the existing evaluation is not agnostic to the different components, thus any conclusions about the relative prediction quality of the QPP methods should be taken with a grain of salt. ","tags":["\"Query Performance Prediction\"","\"Evaluation\"","\"Query Variations\""],"title":"New Perspectives to Query Performance Prediction Evaluation","type":"publication"},{"authors":["Guglielmo Faggioli","Oleg Zendel","J. Shane Culpepper","Nicola Ferro","Falk Scholer"],"categories":null,"content":"","date":1616803200,"expirydate":-62135596800,"kind":"page","lang":"en","lastmod":1616803200,"objectID":"5628fef55b3f8b094073d60d6aac5e95","permalink":"https://zendelo.github.io/publication/qppanova/","publishdate":"2021-03-27T00:00:00Z","relpermalink":"/publication/qppanova/","section":"publication","summary":"Query Performance Prediction (QPP) has been studied extensively in the IR community over the last two decades. A by-product of this research is a methodology to evaluate the effectiveness of QPP techniques. In this paper, we re-examine the existing evaluation methodology commonly used for QPP, and propose a new approach. Our key idea is to model QPP performance as a distribution instead of relying on point estimates. Our work demonstrates important statistical implications, and overcomes key limitations imposed by the currently used correlation-based point-estimate evaluation approaches. We also explore the potential benefits of using multiple query formulations and ANalysis Of VAriance (ANOVA) modeling in order to measure interactions between multiple factors. The resulting statistical analysis combined with a novel evaluation framework demonstrates the merits of modeling QPP performance as distributions, and enables detailed statistical ANOVA models for comparative analyses to be created.","tags":[],"title":"An Enhanced Evaluation Framework for Query Performance Prediction","type":"publication"},{"authors":["Oleg Zendel","Yaroslav Fyodorov","Fiana Raiber","Natalia Silberstein","Oren Somekh","Ali Tabaja"],"categories":null,"content":"","date":1601510400,"expirydate":-62135596800,"kind":"page","lang":"en","lastmod":1601510400,"objectID":"d6bac7ea3431fd89d3719ff1c61a5489","permalink":"https://zendelo.github.io/publication/adclosepred/","publishdate":"2020-10-01T00:00:00Z","relpermalink":"/publication/adclosepred/","section":"publication","summary":"Online advertising systems often provide means for users to close ads and also leave feedback. Although closing ads requires additional user engagement and usually indicates a poor user experience, ad closes are not as scarce as one might expect. Recently it was shown that penalizing ads with high closing likelihood during auctions may substantially reduce the number of ad closes while maintaining a small predefined revenue loss. In this work, we focus on email since this is the property in which most ad closes occur. Using data collected from a major email provider, we present interesting insights about the interplay between ad closes in email and email-related user actions. In particular, we explore the merits of integrating information derived from user actions in email for ad-close prediction. Thorough performance evaluation reveals that incorporating such signals significantly improves ad-close prediction quality over previously reported results.","tags":[],"title":"Leveraging User Email Actions to Improve Ad-Close Prediction","type":"publication"},{"authors":["Oleg Zendel","Anna Shtok","Fiana Raiber","Oren Kurland","J. Shane Culpepper"],"categories":null,"content":"","date":1561939200,"expirydate":-62135596800,"kind":"page","lang":"en","lastmod":1561939200,"objectID":"cecc92aee465c0e6348a6c59271d69f3","permalink":"https://zendelo.github.io/publication/qppvar/","publishdate":"2019-07-01T00:00:00Z","relpermalink":"/publication/qppvar/","section":"publication","summary":"The query performance prediction (QPP) task is to estimate the effectiveness of a search performed in response to a query with no relevance judgments. Existing QPP methods do not account for the effectiveness of a query in representing the underlying information need. We demonstrate the far-reaching implications of this reality using standard TREC-based evaluation of QPP methods: their relative prediction quality patterns vary with respect to the effectiveness of queries used to represent the information needs. Motivated by our findings, we revise the basic probabilistic formulation of the QPP task by accounting for the information need and its connection to the query. We further explore this connection by proposing a novel QPP approach that utilizes information about a set of queries representing the same information need. Predictors instantiated from our approach using a wide variety of existing QPP methods post prediction quality that substantially transcends that of applying these methods, as is standard, using a single query representing the information need. Additional in-depth empirical analysis of different aspects of our approach further attests to the crucial role of query effectiveness in QPP.","tags":[],"title":"Information Needs, Queries, and Query Performance Prediction","type":"publication"},{"authors":null,"categories":null,"content":"","date":-62135596800,"expirydate":-62135596800,"kind":"page","lang":"en","lastmod":-62135596800,"objectID":"f26b5133c34eec1aa0a09390a36c2ade","permalink":"https://zendelo.github.io/admin/","publishdate":"0001-01-01T00:00:00Z","relpermalink":"/admin/","section":"","summary":"","tags":null,"title":"","type":"wowchemycms"}]